{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b46dcd",
   "metadata": {},
   "source": [
    "'''1. Analyze business.json to find the total number of reviews for all businesses. The output\n",
    "should be in the formof a Spark DataFrame with one value representing the count.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c7b6f",
   "metadata": {},
   "source": [
    "ssh gegy@130.226.142.166 -p 8022 -i sshkey\n",
    "pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = spark.read.json(\"/datasets/yelp/business.json\")\n",
    "\n",
    "# get the column names in the file\n",
    "\n",
    "bdf.agg({'review_count': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e48362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analyze business.json to find all businesses that have received 5 stars and that have\\nbeen reviewed by 1000 or more users. The output should be in the formof DataFrame of\\n(name, stars, review count).'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Analyze business.json to find all businesses that have received 5 stars and that have\n",
    "been reviewed by 1000 or more users. The output should be in the formof DataFrame of\n",
    "(name, stars, review count).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c40c11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16456/3652285480.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbdft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stars == 5 and review_count >= 1000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stars == 5 and review_count >= 1000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stars\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"review_count\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bdf' is not defined"
     ]
    }
   ],
   "source": [
    "bdft = bdf.filter('stars == 5 and review_count >= 1000')\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "bdf.filter('stars == 5 and review_count >= 1000').select(col(\"name\"),col(\"stars\"),col(\"review_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f991b8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analyze user.json to find the influencerswho have writtenmore than 1000 reviews. The\\noutput should be in the formof DataFrame of user id.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Analyze user.json to find the influencerswho have writtenmore than 1000 reviews. The\n",
    "output should be in the formof DataFrame of user id.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d8f299",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16456/2095000248.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mudf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/datasets/yelp/user.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mudf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'review_count > 1000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "udf = spark.read.json(\"/datasets/yelp/user.json\")\n",
    "\n",
    "udf.filter('review_count > 1000').select(col(\"user_id\")).show()\n",
    "\n",
    "udfres = udf.filter('review_count > 1000').select(col(\"user_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae5827a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analyze review.json, business.json, and a view created from your answer to Q3 to\\nfind the businesses that have been reviewed by more than 5 influencer users.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Analyze review.json, business.json, and a view created from your answer to Q3 to\n",
    "find the businesses that have been reviewed by more than 5 influencer users.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29204d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = spark.read.json(\"/datasets/yelp/review.json\") # contains the reviews \n",
    "# rdf.schema.names\n",
    "# rdf business_id, review_id ,user_id\n",
    "# rdf.count() - 6685900 \n",
    "# bdf.count() - 192609 # business_id\n",
    "\n",
    "# udfr # 1420\n",
    "df_bus_merge = rdf.join(bdf,['business_id'],how='inner')\n",
    "# df_bus_merge.count() # 6685900\n",
    "# df_bus_merge.schema.names\n",
    "df_merged = df_bus_merge.join(udfres,['user_id'],how='inner')\n",
    "# df_merged.count() 133576\n",
    "df_merged_count = df_merged.groupBy('business_id').count()\n",
    "#\n",
    "df_merged_count.filter('count > 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9211e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analyze review.json and user.json to find an ordered list of users based on the average\\nstar counts they have given in all their reviews.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Analyze review.json and user.json to find an ordered list of users based on the average\n",
    "star counts they have given in all their reviews.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686effc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf.count() - 6685900 \n",
    "# udf.count() - 1637138\n",
    "# udf.schema.names # average_stars\n",
    "# udf.select(\"average_stars\").show()\n",
    "# I dont think the review.json is necceserry here since users df contains the average stars\n",
    "rdf.show()\n",
    "u_temp = udf.sort(col(\"average_stars\").desc())\n",
    "# I made a new df since if you print it it looks like a mess\n",
    "u_temp.select(col(\"average_stars\"),col(\"user_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274a311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27e5f56",
   "metadata": {},
   "source": [
    "## 3.2.1 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50718ca",
   "metadata": {},
   "source": [
    "What is the percentage of reviews containing a variant of the word \"authentic\"? How\n",
    "many reviews contain the string \"legitimate\" grouped by businesses type (type of cuisine)?"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f8ee442f",
   "metadata": {},
   "source": [
    "PROBLEM: No \"cusine type\"  or \"business type\" in the dataset\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b96229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "rdf = spark.read.json(\"/datasets/yelp/review.json\")\n",
    "rdf.createOrReplaceTempView(\"reviews\")\n",
    "bdf = spark.read.json(\"/datasets/yelp/business.json\")\n",
    "bdf.createOrReplaceTempView(\"business\")\n",
    "\n",
    "# \n",
    "bdf.select(col(\"categories\")).show()\n",
    "\n",
    "# example line \n",
    "rsql_df = spark.sql(\"SELECT * FROM reviews WHERE funny = 5\") # this is just an exaple\n",
    "rsql_df.select(col(\"funny\"),col(\"user_id\")).show()\n",
    "\n",
    "\n",
    "# Solution\n",
    "df1 = spark.sql(\"SELECT * FROM reviews\")\n",
    "df1.schema.names\n",
    "df2 = spark.sql(\"SELECT * FROM reviews WHERE text LIKE '%authentic%'\")\n",
    "# its super sloooooooowwwww, how can I add these to variables ? \n",
    "print(\"Ratio of reviews which contains 'authetnic' is \", df1.count() / df2.count())\n",
    "\n",
    "\n",
    "\n",
    "# solution 2 # its not gooooood\n",
    "all_reviews_count = spark.sql(\"SELECT count(*) FROM reviews\")\n",
    "auth_reviews_count = spark.sql(\"SELECT count(*) FROM reviews WHERE text LIKE '%authentic%'\")\n",
    "# still super sloooow \n",
    "t = spark.sql(\"SET @res = (SELECT count(*) FROM reviews)\")\n",
    "\n",
    "############################################################## b\n",
    "# merge\n",
    "df = rdf.join(bdf,['business_id'],how='inner')\n",
    "df.createOrReplaceTempView(\"rewBusiness\")\n",
    "# res is not good, since categories contains list of strings, so I dont know how should we split them by \"cusion type \"\n",
    "res = spark.sql(\"SELECT R.categories, count(R.review_id) FROM rewBusiness R WHERE R.text LIKE '%legitimate%' GROUP BY R.categories\")\n",
    "res = df3.agg({\"count(review_id)\":\"sum\"}).collect()\n",
    "print(res) #??? seems good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = spark.read.format(\"json\").option(\"inferSchema\", \"true\").option(\"multiLine\", \"true\").load(\"/datasets/yelp/business.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = bdf.select(\"categories\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "c_l = []\n",
    "for i in categories:\n",
    "    try:\n",
    "        for c in i.split(\", \"):\n",
    "            c_l.append(c)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "c = Counter(c_l)\n",
    "print(c.most_common(10))\n",
    "\n",
    "#\n",
    "from pyspark.sql.functions import split, explode\n",
    "\n",
    "bdf2 = bdf.withColumn('cat_new',explode(split('categories',', ')))\n",
    "\n",
    "bdf2.select(col('cat_new')).show()\n",
    "\n",
    "rews = spark.sql(\"SELECT * FROM reviews WHERE text LIKE '%legitimate%'\")\n",
    "\n",
    ">>> rews.schema.names\n",
    "# rews.count() --- 4578\n",
    "# ['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text', 'useful', 'user_id']\n",
    "bdf2.schema.names\n",
    "#['address', 'attributes', 'business_id', 'categories', 'city', \n",
    "# 'hours', 'is_open', 'latitude', 'longitude', 'name', 'postal_code', 'review_count', 'stars', 'state', 'cat_new']\n",
    "# bdf2.count() -- 788359\n",
    "merge =  = rews.join(bdf2,['business_id'],how='inner')\n",
    "# merge.count() -- 21663\n",
    "\n",
    "categories = merge.select(\"cat_new\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "from collections import Counter\n",
    "c_l = []\n",
    "for i in categories:\n",
    "    c_l.append(i)\n",
    "\n",
    "c = Counter(c_l)\n",
    "print(c.most_common(40))\n",
    "\n",
    "\" Answer RAW\"\n",
    "# [('Restaurants', 2250), ('Food', 829), ('Nightlife', 750), ('Bars', 661), ('Shopping', 419), ('Event Planning & Services', 390), ('Home Services', 379), ('American (New)', 360), ('Arts & Entertainment', 337), ('American (Traditional)', 323), ('Hotels & Travel', 319), ('Automotive', 316), ('Breakfast & Brunch', 309), ('Beauty & Spas', 307), ('Health & Medical', 280), ('Sandwiches', 238), ('Pizza', 217), ('Italian', 209), ('Mexican', 207), ('Local Services', 203)]\n",
    ">>> print(c.most_common(40))\n",
    "[('Restaurants', 2250), ('Food', 829), ('Nightlife', 750), ('Bars', 661), ('Shopping', 419), \n",
    " ('Event Planning & Services', 390), ('Home Services', 379), ('American (New)', 360), \n",
    " ('Arts & Entertainment', 337), ('American (Traditional)', 323), \n",
    " ('Hotels & Travel', 319), ('Automotive', 316), ('Breakfast & Brunch', 309), \n",
    " ('Beauty & Spas', 307), ('Health & Medical', 280), ('Sandwiches', 238), \n",
    " ('Pizza', 217), ('Italian', 209), ('Mexican', 207), ('Local Services', 203), \n",
    " ('Active Life', 196), ('Coffee & Tea', 194), ('Hotels', 189), ('Burgers', 180), \n",
    " ('Auto Repair', 172), ('Japanese', 166), ('Seafood', 157), ('Real Estate', 152), \n",
    " ('Sushi Bars', 137), ('Chinese', 136), ('Desserts', 133), ('Asian Fusion', 130), \n",
    " ('Specialty Food', 126), ('Lounges', 124), ('Professional Services', 123), \n",
    " ('Steakhouses', 116), ('Cafes', 114), ('Doctors', 114), ('Casinos', 110), ('Wine & Spirits', 109)]\n",
    "\n",
    "restaurrant_categories = \n",
    "'Breakfast & Brunch'\n",
    "'Sandwiches'\n",
    "'Coffee & Tea'\n",
    "'Burgers'\n",
    "'Seafood'\n",
    "'Sushi Bars'\n",
    "'Steakhouses'\n",
    "\n",
    "cousine_types = [\n",
    "'American (New)',\n",
    "'American (Traditional)',\n",
    "'Italian',\n",
    "'Mexican',\n",
    "'Japanese',\n",
    "'Chinese',\n",
    "'Thai',\n",
    "'Indian',\n",
    "'French',\n",
    "'Korean',\n",
    "'Mediterranean',\n",
    "'Soul']\n",
    "\n",
    "m = merge.filter(merge.cat_new.isin(cousine_types))\n",
    "m.groupBy(\"cat_new\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a1d1b",
   "metadata": {},
   "source": [
    "Is there a difference in the amount of authenticity language used in the different areas?\n",
    "(e.g., by state, north/south, urban/rural)\n",
    "Note: As part of answering this question, you should compute the full cube combining\n",
    "the location of the business and whether the review contains authenticity language, and\n",
    "use this to aggregate their counts per state and city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ddd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = spark.read.json(\"/datasets/yelp/review.json\")\n",
    "rdf.createOrReplaceTempView(\"reviews\")\n",
    "bdf = spark.read.json(\"/datasets/yelp/business.json\")\n",
    "bdf.createOrReplaceTempView(\"business\")\n",
    "\n",
    "rdf_a = spark.sql(\"SELECT * FROM reviews WHERE text LIKE '%authentic%' OR text LIKE '%legitimate%' OR text LIKE '%accent%'\")\n",
    "# count = 121075\n",
    "bdf = spark.sql(\"SELECT * FROM business WHERE state IS NOT NULL OR city IS NOT NULL\")\n",
    "\n",
    "merge_auth = rdf_a.join(bdf,['business_id'],how='inner')\n",
    "# res = merge.groupBy(\"state\",\"city\").agg({'review_id': 'sum'}).collect()\n",
    "auth_df = merge_auth.cube(\"state\").count().orderBy(\"state\") # it can have multipe columns, I just skipped it\n",
    "auth_df = auth_df.withColumnRenamed(\"count\",\"auth_lan_count\")\n",
    "auth_df = auth_df.withColumnRenamed(\"state\",\"state_auth\")\n",
    "\n",
    "# sec part\n",
    "rdf = spark.sql(\"SELECT * FROM reviews\")\n",
    "# count 6685900\n",
    "merge_all = rdf.join(bdf,['business_id'],how='inner')\n",
    "all_r = merge_all.cube(\"state\").count().orderBy(\"state\") # it can have multipe columns, I just skipped it\n",
    "all_r = all_r.withColumnRenamed(\"count\",\"all_lan_count\")\n",
    "\n",
    "all_r.show()\n",
    "auth_df.show()\n",
    "\n",
    "#uni = all_r.union(auth_df).distinct()\n",
    "# all_r.join(auth_df,all_r.state ==  auth_df.state,\"fullouter\").show(truncate=False)\n",
    "join = all_r.join(auth_df,all_r.state ==  auth_df.state_auth,\"fullouter\")\n",
    "join = join.fillna(0, subset=['all_lan_count'])\\\n",
    "       .fillna(0, subset=['auth_lan_count'])\n",
    "\n",
    "from pyspark.sql.functions import coalesce\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import lit\n",
    "#join = join.withColumn('Ratio of using auth language compared to all review', coalesce(col('auth_lan_count'), lit(0)) / coalesce(col('all_lan_count'), lit(1)))\n",
    "join = join.withColumn('Ratio', (coalesce(col('auth_lan_count'), lit(0)) / coalesce(col('all_lan_count'), lit(1))*100))\n",
    "\n",
    "print(\"Result of ratio of using authenticity language compared to all review in state level\")\n",
    "join.sort(join.Ratio.desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9adfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[('Restaurants', 2250), ('Food', 829), ('Nightlife', 750), ('Bars', 661), ('Shopping', 419), \n",
    " ('Event Planning & Services', 390), ('Home Services', 379), ('American (New)', 360), \n",
    " ('Arts & Entertainment', 337), ('American (Traditional)', 323), ('Hotels & Travel', 319), \n",
    " ('Automotive', 316), ('Breakfast & Brunch', 309), ('Beauty & Spas', 307), ('Health & Medical', 280),\n",
    " ('Sandwiches', 238), ('Pizza', 217), ('Italian', 209), ('Mexican', 207), ('Local Services', 203), \n",
    " ('Active Life', 196), ('Coffee & Tea', 194), ('Hotels', 189), ('Burgers', 180), \n",
    " ('Auto Repair', 172), ('Japanese', 166), ('Seafood', 157), ('Real Estate', 152), \n",
    " ('Sushi Bars', 137), ('Chinese', 136), ('Desserts', 133), ('Asian Fusion', 130), \n",
    " ('Specialty Food', 126), ('Lounges', 124), ('Professional Services', 123), \n",
    " ('Steakhouses', 116), ('Cafes', 114), ('Doctors', 114), ('Casinos', 110), \n",
    " ('Wine & Spirits', 109), ('Beer', 109), ('Barbeque', 108), ('Salad', 108), \n",
    " ('Bakeries', 108), ('Car Dealers', 105), ('Fast Food', 103), ('Pubs', 102), \n",
    " ('Cocktail Bars', 101), ('Massage', 93), ('Sports Bars', 93), ('Caterers', 90), \n",
    " ('Venues & Event Spaces', 89), ('Home & Garden', 86), ('Day Spas', 85), \n",
    " ('Vegetarian', 82), ('Music Venues', 80), ('Fitness & Instruction', 80),\n",
    " ('Hair Salons', 79), ('Fashion', 79), ('Apartments', 77), ('Pets', 77), \n",
    " ('Vegan', 76), ('Wine Bars', 74), ('Mediterranean', 74), ('Chicken Wings', 74), \n",
    " ('Local Flavor', 73), ('Dance Clubs', 73), ('Oil Change Stations', 70), \n",
    " ('Thai', 68), ('Buffets', 67), ('Auto Parts & Supplies', 67),\n",
    " ('Juice Bars & Smoothies', 65), ('Diners', 64), ('Financial Services', 63), \n",
    " ('Resorts', 61), ('Delis', 60), ('Grocery', 59), ('Korean', 59), \n",
    " ('Ice Cream & Frozen Yogurt', 58), ('Gastropubs', 58), ('Nail Salons', 58), \n",
    " ('Gluten-Free', 55), ('Performing Arts', 54), ('Hair Removal', 54), \n",
    " ('Skin Care', 54), ('Canadian (New)', 54), ('Vietnamese', 53), \n",
    " ('Gyms', 52), ('Medical Centers', 51), ('Tires', 49), \n",
    " ('Contractors', 49), ('Pet Services', 48), ('Transportation', 47), \n",
    " ('Education', 47), ('French', 47), ('Indian', 46), \n",
    " ('Car Rental', 46), ('Noodles', 45), ('Ethnic Food', 45), ('Soup', 44)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58238303",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "rdd=spark.sparkContext.parallelize(categories)\n",
    "print(rdd.take(1))\n",
    "rdd2=rdd.flatMap(lambda x: x.split(\", \"))\n",
    "print(rdd2.take(1))\n",
    "rdd3=rdd2.flatMap(lambda x: x.split(\", \"))\n",
    "list_of_categories = []\n",
    "for element in rdd.collect():\n",
    "    list_of_categories.append(element)\n",
    "c = 0\n",
    "\n",
    "for i in list_of_categories:\n",
    "    if len(i) == 0:\n",
    "        continue\n",
    "        c +=1\n",
    "    else:\n",
    "        print(c)\n",
    "        print(i.split())\n",
    "        c +=1\n",
    "        \n",
    "        \n",
    "\n",
    "for i in categories:\n",
    "    try:\n",
    "        print(i.split(\", \"))\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "        \n",
    "        \n",
    "from collections import Counter\n",
    "l = []\n",
    "for i in categories:\n",
    "    t = str(i)\n",
    "    for c in t.split(\",\"):\n",
    "        l.append(c)\n",
    "        \n",
    "c = Counter(l)\n",
    "print(c.most_common(40))\n",
    "\n",
    "\n",
    "rdd=spark.sparkContext.parallelize(bdf.select(col(\"categories\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7593f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2=bdf.select(col(\"categories\")).flatMap(lambda x: x.split(\" \"))\n",
    "for element in rdd2.collect():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb695fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How many reviews contain the string 'legitimate' grouped by restaurant categories?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"How many reviews contain the string 'legitimate' grouped by restaurant categories?\"\n",
    "# since categories are a list of strings ( check above ) I dont know how should I handle this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b84f65e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7212/3183944655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"he, word\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "s = [\"he, word\"]\n",
    "s.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f56144de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "for i in s:\n",
    "    t = str(i)\n",
    "    for c in t.split(\", \"):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc60a1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>x_number</th>\n",
       "      <th>y</th>\n",
       "      <th>y_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>j</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x  x_number    y  y_number\n",
       "0    a       2.0  NaN       NaN\n",
       "1    b       1.0  NaN       NaN\n",
       "2    c       2.0  NaN       NaN\n",
       "3    e       1.0  NaN       NaN\n",
       "4    d       1.0  NaN       NaN\n",
       "0  NaN       NaN    h       2.0\n",
       "1  NaN       NaN    j       3.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.cbook import flatten\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "din={'x':[['a','b','c'],['a','e','d', 'c']], 'y': [['h','j'],['h','j','j']]}\n",
    "\n",
    "def foo(x):\n",
    "    df = pd.DataFrame()\n",
    "    for a,i in x.items() :\n",
    "        u=pd.DataFrame.from_dict(dict(Counter([*flatten(i)])), orient ='index').reset_index().rename(columns ={'index':a,0:str(a)+'_number'})\n",
    "        df=pd.concat([df,u])\n",
    "    return df\n",
    "foo(din)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75953e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
